---
title: "Replication of Experiment 3 by Jakesch et. al. (2019, ACM CHI Conference on Human Factors in Computing Systems)"
author: "Jacob Ritchie (jritchie@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

  
###Justification and Relevance to Research

I have chosen a paper from the 2019 ACM CHI Conference^[One of the largest and most selective publication venues in my field, for details see: https://tinyurl.com/justify-chi and https://tinyurl.com/justify-chi-one-pager .]. This paper ("AI-Mediated Communication: How the Perception
that Profile Text was Written by AI Affects
Trustworthiness") shows evidence for what the authors call "The Replicant Effect": that the belief that a piece of text (in their case, a profile for an AirBnB host) is AI-generated decreases reported trust, but only if participants believe it is part of a *mixed set* where *only some* of the pieces of text are AI-generated. If participants are told that *all* profiles are AI-generated, the reported trust does not differ from the case where they are told that all profiles are human-generated. A large part of my future research agenda will be to measure user preferences and opinions that might influence the adoption of new technologies enabled by recent advances in machine learning. Machine learning systems are becoming much better at generating human-like text, which has some exciting applications, but is also a source of great concern (especially in the context of political disinformation). This particular result gives interesting context about when users find the use of AI-generated text acceptable and unacceptable, and I think attempting to replicate it would be interesting both to myself and to the broader research communities for Human-Computer Interaction and Human-Centered AI.

###Methods

The experiment will be run on Amazon Mechanical Turk (mTurk). Each participant will be shown ten AirBnB profiles, five of which are "human-like" and five of which are "AI-like"^[These were drawn from a larger corpus of real, human-generated AirBnB profiles and then, in a previous mTurk task, separated into two groups based on how likely crowd workers thought they were to be AI-generated, using the same AI score question as in the *primed condition*. Each participant will be shown five profiles that are randomly selected from the fifteen highest and lowest scoring profiles (see Table 1 for two examples).] (see Table 1). 
There are four between-participant conditions - a *control* condition where participants are told that all profiles are human-generated, an *unlabeled* condition where participants are told that some are "AI-generated" (but not which ones), a *labeled* condition where they are told which profiles are "AI-generated" and a *primed* condition where participants give each profile a Likert scale *AI score* (ranging from "Definitely Human-written" to "Definitely AI-generated") before they indicate how much they trust that profile. For each profile they will report a trustworthiness score based on the mean of three Likert scale questions (about the host's *ability*, *benevolence*, and *integrity*). They will also complete two sets of questions at the end of the experiment to measure their attitude toward AI and their generalized trust level. I will then fit a generalized linear mixed model (GLMM) with per-participant random effects to analyze the profile trustworthiness scores (in the original paper this analyis found significant interaction effects - i.e., all three treatment conditions caused a decrease in reported trust, but only for the "AI-like" host profiles).

```{r, include=FALSE}
library(dplyr)
library(kableExtra)
```


```{r, echo=FALSE}
reviews <- tibble("AI Score"=c("5 (most AI-like)", "1.75 (most human-like)"), "Profile Text"=c("Hey, I'm an health nut and entrepreneur. Enjoy cooking, reading, writing. Favorite restaurant nearby: Momofuku Ssam bar. Favorite weird activity nearby: Russian Baths on E. 10th St. Heaven is three grocery stores and a farmer's market within two blocks (Trader Joe's, Whole Foods, Westside Market, farmer's market", "I am a musician that travels with my band a lot. I have a place in Hawaii as well that I spend time in. I'm clean. funky. and a fun artist. Love yoga, books, writing, singing, dancing, dj'ing, art, and the list goes onnn. "))
knitr::kable(reviews,caption="Table 1: The top 'human-like' and 'AI-like' sample profiles used in Experiment 3.") %>%  column_spec(1, width="12em")
```


###Challenges / Concerns

From a technical standpoint, coding and running the experiment is within my comfort level^[I can adapt the project to try and make it more technically challenging if necessary (for example, measuring and analyzing differences in response time to see which profiles participants found difficult to classify, examining differences in response time between the three treatment conditions, or adapting a deep-learning-based language model to generate real "AI-generated" profiles).]. 
However the statistical aspect would be challenging and a good learning experience, since I am not at all familiar with how to use or analyze GLMMs^[For example it seems like a very large portion of the variance explained is due to differences between participants (R^2^ = 0.0095 in the fixed effects model and R^2^ = 0.4873 in the random effects model) - I'm not currently familiar enough with GLMMs to really understand the implications of this.]. My main concern about replicating this paper that is the sample size used in the original paper's Experiment 3 (323 participants, 6 minutes each - 32.3 person-hours of labour) is larger than what is feasible given the course project budget. A preliminary power analysis done with the help of one of the TAs (Julie) indicated that since the observed effect size is large, it might be possible to replicate the experiment with a smaller sample size. I could also focus on only one of the three treatment conditions. Another challenge is that succesfully replicating Experiment 3 will only confirm half of the 'Replicant Effect'. It won't show the negative case (that when participants believe that all profiles are AI-generated, they report the same level of trust as when they believe that they are all human-generated). This was done in the paper's Experiment 1, by running an experiment with a very large sample size (N=527) that failed to reject the null hypothesis. My understanding is that using Bayesian statistical methods there are ways to run experiments that provide evidence that a certain effect does not exist, but I am not familiar with these methods - though I would be interested in exploring this as part of the project. 

## Links

**Repo:** https://github.com/psych251/jakesch2019/

**Original Paper:** https://github.com/psych251/jakesch2019/blob/master/original_paper/jakesch2019.pdf
<!--

###Power Analysis

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

###Planned Sample

Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

###Materials

All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

###Procedure	

Can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

###Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.

###Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions

####Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
-->